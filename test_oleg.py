import requests
import json
from qdrant_client import QdrantClient
from qdrant_client.http import models

class SimpleRAGClient:
    def __init__(self, qdrant_url: str, qdrant_api_key: str = None, 
                 collection_name: str = "", 
                 ollama_url: str = "http://", 
                 ollama_model: str = "",
                 embed_model: str = ""):
        """
        Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ RAG ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ° Ñ Qdrant Ğ¿Ğ¾ URL
        
        Args:
            qdrant_url: URL Qdrant ÑĞµÑ€Ğ²ĞµÑ€Ğ° (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, "http://localhost:6333")
            qdrant_api_key: API ĞºĞ»ÑÑ‡ Qdrant (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)
            collection_name: ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ğ¸
            ollama_url: URL Ollama ÑĞµÑ€Ğ²ĞµÑ€Ğ°
            ollama_model: ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ²
            embed_model: ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²
        """
        # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Qdrant ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°
        self.client = QdrantClient(
            url=qdrant_url,
            api_key=qdrant_api_key,
            timeout=60  # Ğ£Ğ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ‚Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚
        )
        self.collection_name = collection_name
        
        # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ollama
        self.ollama_url = ollama_url
        self.ollama_model = ollama_model
        self.embed_model = embed_model
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğ¹
        self._check_connections()
    
    def _check_connections(self):
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğ¹ Ñ Qdrant Ğ¸ Ollama"""
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Qdrant
        try:
            health = self.client.get_liveness()
            print(f"âœ… Qdrant Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½: {health}")
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ğ¸
            collections = self.client.get_collections()
            collection_names = [col.name for col in collections.collections]
            if self.collection_name in collection_names:
                print(f"âœ… ĞšĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ '{self.collection_name}' Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°")
            else:
                print(f"âŒ ĞšĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ '{self.collection_name}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°")
                print(f"Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ğ¸: {collection_names}")
                
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº Qdrant: {e}")
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ollama
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=10)
            if response.status_code == 200:
                models = response.json().get('models', [])
                print(f"âœ… Ollama Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½. ĞœĞ¾Ğ´ĞµĞ»Ğ¸: {[m['name'] for m in models]}")
            else:
                print("âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº Ollama")
        except Exception as e:
            print(f"âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğº Ollama: {e}")
    
    def get_embedding(self, text: str):
        """
        ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ° Ğ¸Ğ· Ollama
        """
        payload = {
            "model": self.embed_model,
            "prompt": text
        }
        
        try:
            response = requests.post(
                f"{self.ollama_url}/api/embeddings",
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                return response.json().get('embedding', [])
            else:
                print(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº Ollama Ğ´Ğ»Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²: {e}")
            return []
    
    def search_similar(self, query: str, limit: int = 5, score_threshold: float = 0.5):
        """ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ¸Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² Qdrant Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°Ğ¼Ğ¸ Ğ¸Ğ· Ollama"""
        query_embedding = self.get_embedding(query)
        
        if not query_embedding:
            print("âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°")
            return []
        
        try:
            search_result = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_embedding,
                limit=limit,
                score_threshold=score_threshold
            )
            
            return search_result
            
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ² Qdrant: {e}")
            return []
    
    def retrieve_context(self, query: str, limit: int = 3, min_score: float = 0.6):
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¸Ğ· Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ±Ğ°Ğ·Ñ‹"""
        results = self.search_similar(query, limit, min_score)
        
        if not results:
            print("âš ï¸  ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²")
            return ""
        
        context_parts = []
        for result in results:
            if result.payload and result.score >= min_score:
                # ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‹ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ°
                text = (result.payload.get('text') or 
                        result.payload.get('content') or 
                        result.payload.get('document') or 
                        str(result.payload))
                if text:
                    source = result.payload.get('source', 'Unknown')
                    score = f"{result.score:.3f}"
                    context_parts.append(f"[Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº: {source}, ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚ÑŒ: {score}] {text}")
        
        return "\n\n".join(context_parts)
    
    def generate_with_ollama(self, prompt: str, context: str = ""):
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ollama"""
        if not context:
            return "âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ½Ğ° ÑÑ‚Ğ¾Ñ‚ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ."
        
        full_prompt = f"""Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¸ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾.

ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚:
{context}

Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ: {prompt}

ĞÑ‚Ğ²ĞµÑ‚:"""
        
        payload = {
            "model": self.ollama_model,
            "prompt": full_prompt,
            "stream": False,
            "options": {
                "temperature": 0.1,
                "top_p": 0.9,
                "num_ctx": 4096
            }
        }
        
        try:
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=payload,
                timeout=120
            )
            
            if response.status_code == 200:
                return response.json().get('response', 'ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°')
            else:
                return f"ĞÑˆĞ¸Ğ±ĞºĞ° Ollama: {response.status_code}"
                
        except Exception as e:
            return f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº Ollama: {e}"
    
    def ask_question(self, query: str, limit_context: int = 3, min_score: float = 0.6):
        """
        ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ñ†Ğ¸ĞºĞ» RAG: Ğ¿Ğ¾Ğ¸ÑĞº ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° + Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°
        """
        print(f"ğŸ” ĞŸĞ¾Ğ¸ÑĞº ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ´Ğ»Ñ: '{query}'")
        context = self.retrieve_context(query, limit_context, min_score)
        
        if not context:
            return {
                "question": query,
                "answer": "âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ.",
                "context": "",
                "context_sources": [],
                "found_documents": 0
            }
        
        print("ğŸ§  Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ñ Ollama...")
        answer = self.generate_with_ollama(query, context)
        
        return {
            "question": query,
            "answer": answer,
            "context": context,
            "context_sources": self._extract_sources(context),
            "found_documents": len(context.split('\n\n')) if context else 0
        }
    
    def _extract_sources(self, context: str):
        """Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ² Ğ¸Ğ· ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°"""
        sources = []
        lines = context.split('\n')
        for line in lines:
            if line.startswith('[Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº:'):
                source = line.split(',')[0].replace('[Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº:', '').strip()
                if source and source not in sources:
                    sources.append(source)
        return sources

# Ğ£Ğ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
class QuickRAG:
    def __init__(self, qdrant_url: str, qdrant_api_key: str = None,
                 ollama_model: str = "llama2",
                 embed_model: str = "mxbai-embed-large"):
        self.client = QdrantClient(url=qdrant_url, api_key=qdrant_api_key)
        self.ollama_url = "http://localhost:11434"
        self.ollama_model = ollama_model
        self.embed_model = embed_model
    
    def get_embedding(self, text: str):
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ° Ğ¸Ğ· Ollama"""
        try:
            response = requests.post(
                f"{self.ollama_url}/api/embeddings",
                json={"model": self.embed_model, "prompt": text},
                timeout=30
            )
            return response.json().get('embedding', []) if response.status_code == 200 else []
        except:
            return []
    
    def ask(self, question: str, top_k: int = 3):
        """Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ-Ğ¾Ñ‚Ğ²ĞµÑ‚"""
        # ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ° Ğ¸ Ğ¿Ğ¾Ğ¸ÑĞº
        embedding = self.get_embedding(question)
        if not embedding:
            return "âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°"
        
        try:
            results = self.client.search(
                collection_name="my_collection",
                query_vector=embedding,
                limit=top_k,
                score_threshold=0.5
            )
            
            # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°
            context = "\n".join([
                f"- {hit.payload.get('text', hit.payload.get('content', ''))} (ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚ÑŒ: {hit.score:.3f})" 
                for hit in results if hit.payload and hit.score > 0.5
            ])
            
            if not context:
                return "âŒ ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸"
            
            # Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°
            prompt = f"""ĞÑ‚Ğ²ĞµÑ‚ÑŒ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚:

ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚:
{context}

Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ: {question}

ĞÑ‚Ğ²ĞµÑ‚:"""
            
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json={
                    "model": self.ollama_model,
                    "prompt": prompt,
                    "stream": False
                },
                timeout=60
            )
            
            if response.status_code == 200:
                answer = response.json().get('response', 'ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚')
                return f"ğŸ¤– ĞÑ‚Ğ²ĞµÑ‚: {answer}\n\nğŸ“š ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²: {len(results)}"
            else:
                return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸: {response.status_code}"
                
        except Exception as e:
            return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Qdrant: {e}"

# ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
if __name__ == "__main__":
    # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ° Ñ Qdrant Ğ¿Ğ¾ URL
    rag_client = SimpleRAGClient(
        qdrant_url="http://",  # Ğ¸Ğ»Ğ¸ Ğ²Ğ°Ñˆ URL Qdrant
        collection_name="",
        ollama_model="",
        embed_model=""
    )
    
    # ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°
    question = "ĞºĞ°ĞºĞ°Ñ Ñ„Ğ¸Ñ€Ğ¼Ğ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ 'Ğ”ÑƒĞ³Ğ¾Ğ³Ğ°ÑĞ½Ğ¸Ğ¹ Ñ€ĞµĞ°ĞºÑ‚Ğ¾Ñ€ 35 ĞºĞ’ Ñ‚Ğ¸Ğ¿Ñƒ ASRC 2500'"
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°
    result = rag_client.ask_question(question)
    
    print("=" * 60)
    print(f"â“ Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ: {result['question']}")
    print("=" * 60)
    print(f"ğŸ¤– ĞÑ‚Ğ²ĞµÑ‚: {result['answer']}")
    print("=" * 60)
    print(f"ğŸ“š ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²: {result['found_documents']}")
    if result['context']:
        print("ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ (Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 300 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²):")
        print(result['context'][:300] + "..." if len(result['context']) > 300 else result['context'])
    print("=" * 60)
    print(f"ğŸ”— Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸: {result['context_sources']}")
